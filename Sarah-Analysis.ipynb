{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>Compound_Score</th>\n",
       "      <th>Positive_Score</th>\n",
       "      <th>Negative_Score</th>\n",
       "      <th>Neutral_Score</th>\n",
       "      <th>external_author_id</th>\n",
       "      <th>author</th>\n",
       "      <th>content</th>\n",
       "      <th>region</th>\n",
       "      <th>language</th>\n",
       "      <th>publish_date</th>\n",
       "      <th>following</th>\n",
       "      <th>followers</th>\n",
       "      <th>updates</th>\n",
       "      <th>post_type</th>\n",
       "      <th>account_type</th>\n",
       "      <th>retweet</th>\n",
       "      <th>account_category</th>\n",
       "      <th>new_june_2018</th>\n",
       "      <th>alt_external_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>914580356430536707</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>906000000000000000</td>\n",
       "      <td>10_GOP</td>\n",
       "      <td>\"We have a sitting Democrat US Senator on tria...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>English</td>\n",
       "      <td>2017-10-01 19:58:00</td>\n",
       "      <td>1052</td>\n",
       "      <td>9636</td>\n",
       "      <td>253</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Right</td>\n",
       "      <td>0</td>\n",
       "      <td>RightTroll</td>\n",
       "      <td>0</td>\n",
       "      <td>905874659358453760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>914621840496189440</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>906000000000000000</td>\n",
       "      <td>10_GOP</td>\n",
       "      <td>Marshawn Lynch arrives to game in anti-Trump s...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>English</td>\n",
       "      <td>2017-10-01 22:43:00</td>\n",
       "      <td>1054</td>\n",
       "      <td>9637</td>\n",
       "      <td>254</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Right</td>\n",
       "      <td>0</td>\n",
       "      <td>RightTroll</td>\n",
       "      <td>0</td>\n",
       "      <td>905874659358453760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>914623490375979008</td>\n",
       "      <td>-0.1531</td>\n",
       "      <td>0.126</td>\n",
       "      <td>0.198</td>\n",
       "      <td>0.676</td>\n",
       "      <td>906000000000000000</td>\n",
       "      <td>10_GOP</td>\n",
       "      <td>Daughter of fallen Navy Sailor delivers powerf...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>English</td>\n",
       "      <td>2017-10-01 22:50:00</td>\n",
       "      <td>1054</td>\n",
       "      <td>9637</td>\n",
       "      <td>255</td>\n",
       "      <td>RETWEET</td>\n",
       "      <td>Right</td>\n",
       "      <td>1</td>\n",
       "      <td>RightTroll</td>\n",
       "      <td>0</td>\n",
       "      <td>905874659358453760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>914639143690555392</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>906000000000000000</td>\n",
       "      <td>10_GOP</td>\n",
       "      <td>JUST IN: President Trump dedicates Presidents ...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>English</td>\n",
       "      <td>2017-10-01 23:52:00</td>\n",
       "      <td>1062</td>\n",
       "      <td>9642</td>\n",
       "      <td>256</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Right</td>\n",
       "      <td>0</td>\n",
       "      <td>RightTroll</td>\n",
       "      <td>0</td>\n",
       "      <td>905874659358453760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>914312219952861184</td>\n",
       "      <td>0.6399</td>\n",
       "      <td>0.413</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.587</td>\n",
       "      <td>906000000000000000</td>\n",
       "      <td>10_GOP</td>\n",
       "      <td>19,000 RESPECTING our National Anthem! #StandF...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>English</td>\n",
       "      <td>2017-10-01 02:13:00</td>\n",
       "      <td>1050</td>\n",
       "      <td>9645</td>\n",
       "      <td>246</td>\n",
       "      <td>RETWEET</td>\n",
       "      <td>Right</td>\n",
       "      <td>1</td>\n",
       "      <td>RightTroll</td>\n",
       "      <td>0</td>\n",
       "      <td>905874659358453760</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id  Compound_Score  Positive_Score  Negative_Score  \\\n",
       "0  914580356430536707          0.0000           0.000           0.000   \n",
       "1  914621840496189440          0.0000           0.000           0.000   \n",
       "2  914623490375979008         -0.1531           0.126           0.198   \n",
       "3  914639143690555392          0.0000           0.000           0.000   \n",
       "4  914312219952861184          0.6399           0.413           0.000   \n",
       "\n",
       "   Neutral_Score  external_author_id  author  \\\n",
       "0          1.000  906000000000000000  10_GOP   \n",
       "1          1.000  906000000000000000  10_GOP   \n",
       "2          0.676  906000000000000000  10_GOP   \n",
       "3          1.000  906000000000000000  10_GOP   \n",
       "4          0.587  906000000000000000  10_GOP   \n",
       "\n",
       "                                             content   region language  \\\n",
       "0  \"We have a sitting Democrat US Senator on tria...  Unknown  English   \n",
       "1  Marshawn Lynch arrives to game in anti-Trump s...  Unknown  English   \n",
       "2  Daughter of fallen Navy Sailor delivers powerf...  Unknown  English   \n",
       "3  JUST IN: President Trump dedicates Presidents ...  Unknown  English   \n",
       "4  19,000 RESPECTING our National Anthem! #StandF...  Unknown  English   \n",
       "\n",
       "          publish_date  following  followers  updates post_type account_type  \\\n",
       "0  2017-10-01 19:58:00       1052       9636      253       NaN        Right   \n",
       "1  2017-10-01 22:43:00       1054       9637      254       NaN        Right   \n",
       "2  2017-10-01 22:50:00       1054       9637      255   RETWEET        Right   \n",
       "3  2017-10-01 23:52:00       1062       9642      256       NaN        Right   \n",
       "4  2017-10-01 02:13:00       1050       9645      246   RETWEET        Right   \n",
       "\n",
       "   retweet account_category  new_june_2018     alt_external_id  \n",
       "0        0       RightTroll              0  905874659358453760  \n",
       "1        0       RightTroll              0  905874659358453760  \n",
       "2        1       RightTroll              0  905874659358453760  \n",
       "3        0       RightTroll              0  905874659358453760  \n",
       "4        1       RightTroll              0  905874659358453760  "
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "# Dependencies and Setup\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "from spacymoji import Emoji\n",
    "\n",
    "# import data and read to df\n",
    "csv = \"../Output/all_data.csv\"\n",
    "df = pd.read_csv(csv, low_memory=False)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Compound_Score</th>\n",
       "      <th>Positive_Score</th>\n",
       "      <th>Negative_Score</th>\n",
       "      <th>Neutral_Score</th>\n",
       "      <th>updates</th>\n",
       "      <th>following</th>\n",
       "      <th>followers</th>\n",
       "      <th>account_type</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>author</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10_GOP</th>\n",
       "      <td>0.078718</td>\n",
       "      <td>0.131511</td>\n",
       "      <td>0.089804</td>\n",
       "      <td>0.778685</td>\n",
       "      <td>176.500000</td>\n",
       "      <td>985.018817</td>\n",
       "      <td>7044.306452</td>\n",
       "      <td>Right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1D_NICOLE_</th>\n",
       "      <td>0.177359</td>\n",
       "      <td>0.193545</td>\n",
       "      <td>0.069000</td>\n",
       "      <td>0.737455</td>\n",
       "      <td>373.500000</td>\n",
       "      <td>58.500000</td>\n",
       "      <td>51.477273</td>\n",
       "      <td>Koch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1ERIK_LEE</th>\n",
       "      <td>-0.549850</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.214000</td>\n",
       "      <td>0.786000</td>\n",
       "      <td>333.000000</td>\n",
       "      <td>239.000000</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>Right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2NDHALFONION</th>\n",
       "      <td>0.439200</td>\n",
       "      <td>0.186000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.814000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>Right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4EVER_SUSAN</th>\n",
       "      <td>0.042470</td>\n",
       "      <td>0.133794</td>\n",
       "      <td>0.104810</td>\n",
       "      <td>0.761413</td>\n",
       "      <td>37.047619</td>\n",
       "      <td>75.650794</td>\n",
       "      <td>57.777778</td>\n",
       "      <td>Right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4MYSQUAD</th>\n",
       "      <td>-0.055819</td>\n",
       "      <td>0.103039</td>\n",
       "      <td>0.110443</td>\n",
       "      <td>0.786312</td>\n",
       "      <td>2008.561763</td>\n",
       "      <td>2271.423753</td>\n",
       "      <td>1159.036830</td>\n",
       "      <td>Left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666STEVEROGERS</th>\n",
       "      <td>0.021032</td>\n",
       "      <td>0.118129</td>\n",
       "      <td>0.095986</td>\n",
       "      <td>0.785899</td>\n",
       "      <td>85.244604</td>\n",
       "      <td>116.791367</td>\n",
       "      <td>7.741007</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAASSSSSHHH</th>\n",
       "      <td>-0.064954</td>\n",
       "      <td>0.124042</td>\n",
       "      <td>0.155423</td>\n",
       "      <td>0.720563</td>\n",
       "      <td>351.450704</td>\n",
       "      <td>27.633803</td>\n",
       "      <td>40.225352</td>\n",
       "      <td>Koch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AANTIRACIST</th>\n",
       "      <td>0.008194</td>\n",
       "      <td>0.093449</td>\n",
       "      <td>0.086481</td>\n",
       "      <td>0.820066</td>\n",
       "      <td>1378.186901</td>\n",
       "      <td>904.408147</td>\n",
       "      <td>748.006390</td>\n",
       "      <td>Left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AARONALLENALL</th>\n",
       "      <td>-0.117983</td>\n",
       "      <td>0.072000</td>\n",
       "      <td>0.173444</td>\n",
       "      <td>0.754556</td>\n",
       "      <td>329.555556</td>\n",
       "      <td>52.111111</td>\n",
       "      <td>51.333333</td>\n",
       "      <td>Koch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AARON_M1TCHELL</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Koch</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Compound_Score  Positive_Score  Negative_Score  Neutral_Score  \\\n",
       "author                                                                          \n",
       "10_GOP                0.078718        0.131511        0.089804       0.778685   \n",
       "1D_NICOLE_            0.177359        0.193545        0.069000       0.737455   \n",
       "1ERIK_LEE            -0.549850        0.000000        0.214000       0.786000   \n",
       "2NDHALFONION          0.439200        0.186000        0.000000       0.814000   \n",
       "4EVER_SUSAN           0.042470        0.133794        0.104810       0.761413   \n",
       "4MYSQUAD             -0.055819        0.103039        0.110443       0.786312   \n",
       "666STEVEROGERS        0.021032        0.118129        0.095986       0.785899   \n",
       "AAASSSSSHHH          -0.064954        0.124042        0.155423       0.720563   \n",
       "AANTIRACIST           0.008194        0.093449        0.086481       0.820066   \n",
       "AARONALLENALL        -0.117983        0.072000        0.173444       0.754556   \n",
       "AARON_M1TCHELL        0.000000        0.000000        0.000000       1.000000   \n",
       "\n",
       "                    updates    following    followers account_type  \n",
       "author                                                              \n",
       "10_GOP           176.500000   985.018817  7044.306452        Right  \n",
       "1D_NICOLE_       373.500000    58.500000    51.477273         Koch  \n",
       "1ERIK_LEE        333.000000   239.000000    74.000000        Right  \n",
       "2NDHALFONION      10.000000    22.000000     1.000000        Right  \n",
       "4EVER_SUSAN       37.047619    75.650794    57.777778        Right  \n",
       "4MYSQUAD        2008.561763  2271.423753  1159.036830         Left  \n",
       "666STEVEROGERS    85.244604   116.791367     7.741007            ?  \n",
       "AAASSSSSHHH      351.450704    27.633803    40.225352         Koch  \n",
       "AANTIRACIST     1378.186901   904.408147   748.006390         Left  \n",
       "AARONALLENALL    329.555556    52.111111    51.333333         Koch  \n",
       "AARON_M1TCHELL     2.500000    41.000000     0.000000         Koch  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# group the dataframe by account\n",
    "\n",
    "account_df = df[[\"author\", \"Compound_Score\", \"Positive_Score\", \"Negative_Score\", \"Neutral_Score\", \"updates\", \"following\", \"followers\"]]\n",
    "account_type_ref = df[[\"author\", \"account_type\"]].drop_duplicates()\n",
    "account_df = account_df.groupby(df[\"author\"]).mean()\n",
    "account_df = account_df.merge(account_type_ref, left_index=True, right_on='author').set_index('author')\n",
    "\n",
    "account_df.head(11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import and create a default dictionary to store words as it finds them from function below\n",
    "from collections import defaultdict\n",
    "word_counts = defaultdict(int) #template for simpler function code\n",
    "\n",
    "# Load the spaCy model\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# make separate dfs for left and right trolls\n",
    "right_troll_df = df[df[\"account_category\"] == \"RightTroll\"]\n",
    "left_troll_df = df[df[\"account_category\"] == \"LeftTroll\"]\n",
    "\n",
    "# function to run NER \n",
    "def getEntities(tweet):\n",
    "    output = nlp(tweet)\n",
    "    ents = output.ents\n",
    "    return_list = []\n",
    "    for ent in ents:\n",
    "        return_list.append(ent.text.lower())\n",
    "        word_counts[ent.text.lower()] += 1\n",
    "    return return_list\n",
    "\n",
    "# run on a random sample of Left and Right Trolls\n",
    "Right = right_troll_df['content'].sample(n=25000).apply(getEntities)\n",
    "Right_Counts = word_counts #dict for right measurements\n",
    "del word_counts \n",
    "word_counts = defaultdict(int)\n",
    "Left = left_troll_df['content'].sample(n=25000).apply(getEntities)\n",
    "Left_Counts = word_counts #dict for left measurements\n",
    "del word_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1116 - rt\n",
      "801 -  \n",
      "757 - #\n",
      "652 - obama\n",
      "594 - hillary\n",
      "507 - trump\n",
      "421 - maga\n",
      "402 - america\n",
      "382 - cnn\n",
      "291 - us\n",
      "263 - one\n",
      "241 - american\n",
      "239 - gop\n",
      "238 - russia\n",
      "218 - democrats\n",
      "205 - clinton\n",
      "203 - u.s.\n",
      "201 - today\n",
      "194 - fbi\n",
      "187 - 🇺\n",
      "184 - 2\n",
      "183 - americans\n",
      "182 - donald trump\n",
      "180 - first\n",
      "177 - fakenews\n",
      "167 - democrat\n",
      "158 - muslim\n",
      "157 - congress\n",
      "157 - dems\n",
      "157 - hillary clinton\n",
      "145 - lol\n",
      "144 - pjnet\n",
      "137 - antifa\n",
      "133 - nfl\n",
      "131 - 4\n",
      "127 - iran\n",
      "127 - dem\n",
      "126 - north korea\n",
      "126 - charlottesville\n",
      "115 - dnc\n",
      "115 - muslims\n",
      "114 - two\n",
      "112 - ️\n",
      "108 - california\n",
      "107 - republicans\n",
      "105 - #mar\n",
      "102 - msm\n",
      "101 - texas\n",
      "95 - islam\n",
      "95 - israel\n"
     ]
    }
   ],
   "source": [
    "#get the value from the key-value dictionary\n",
    "def getSecond(x):\n",
    "    return x[1]\n",
    "\n",
    "#Get Top Entities from the Right Trolls df and sort by most instances to least\n",
    "top = 50\n",
    "sorted_entities = sorted(Right_Counts.items(), key=getSecond, reverse=True)\n",
    "for ent in sorted_entities[0:top]:\n",
    "    print(\"{} - {}\".format(ent[1], ent[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "733 -  \n",
      "621 - #\n",
      "481 - blacklivesmatter\n",
      "326 - trump\n",
      "314 - today\n",
      "299 - one\n",
      "269 - first\n",
      "231 - 2\n",
      "216 - america\n",
      "215 - us\n",
      "187 - rt\n",
      "166 - ️\n",
      "158 - obama\n",
      "137 - chicago\n",
      "136 - 1\n",
      "135 - 4\n",
      "128 - 2016\n",
      "122 - donald trump\n",
      "122 - gop\n",
      "117 - 3\n",
      "115 - @youtube\n",
      "112 - russia\n",
      "107 - 5\n",
      "105 - tonight\n",
      "105 - trump's\n",
      "105 - american\n",
      "103 - two\n",
      "95 - black\n",
      "90 - 2017\n",
      "90 - u.s.\n",
      "82 - 10\n",
      "75 - americans\n",
      "74 - blm\n",
      "72 - clinton\n",
      "68 - staywoke\n",
      "64 - hillary\n",
      "64 - republicans\n",
      "64 - blackhistorymonth\n",
      "63 - dagr8fm\n",
      "60 - 6\n",
      "60 - texas\n",
      "60 - god\n",
      "58 - @realdonaldtrump\n",
      "57 - tomorrow\n",
      "57 - muslim\n",
      "56 - rapstationradio\n",
      "56 - baltimore\n",
      "55 - \\|\n",
      "55 - fbi\n",
      "53 - @josephjett\n"
     ]
    }
   ],
   "source": [
    "#Get Top Entities from the Left Trolls df and sort by most instances to least\n",
    "top = 50\n",
    "sorted_entities = sorted(Left_Counts.items(), key=getSecond, reverse=True)\n",
    "for ent in sorted_entities[0:top]:\n",
    "    print(\"{} - {}\".format(ent[1], ent[0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Most common words \n",
    "Here are some of the most common words between left and right trolls. The search_terms list below will include different spellings of these words or words that are very closely associated, like if \"trump\" was a most used word, \"donald\" would mean the same thing and be added to this list. I will search all of these words with a function to find content that \"contains\" certain words so that I can see a comprehensive overview of how many tweets mentioned the subjects, and not just the most used word of the subjects below.\n",
    "\n",
    "1. Trump\n",
    "2. BlackLivesMatter\n",
    "3. Hillary\n",
    "4. Wall\n",
    "5. Obama\n",
    "6. America\n",
    "7. Republican\n",
    "8. Democrat\n",
    "9. MAGA\n",
    "10. Islam\n",
    "11. Fake news\n",
    "12. Russia\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a df for the search terms so you can store the frequency that they appear in a search \n",
    "    # and the avg sentiment score that the right and the left associates with them\n",
    "common_words_scored = [\"Subject\", \"Right_Frequency\", \"Left_Frequency\", \"Right_Sentiment\", \"Left_Sentiment\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_terms = {\"Trump\": [\"Trump\", \"Donald\", \"DJT\", \"trump's\", \"realdonaldtrump\"],\n",
    "                \"BlackLivesMatter\": [\"BlackLivesMatter\", \"blacklives\", \"black\", \"blm\", \"get woke\", \"blackhistorymonth\", \"african american\"],\n",
    "                \"Hillary\": [\"Hillary\", \"Clinton\"],\n",
    "                \"Wall\": [\"Wall\", \"build\", \"border\"],\n",
    "                \"Obama\": [\"Obama\", \"obamacare\", \"barack\"],\n",
    "                \"America\": [\"America\", \"USA\", \"united states\", \"merca\", \"u.s.\", \"American\"],\n",
    "                \"Republican\": [\"Republican\", \"gop\", \"conservative\", \"right wing\"],\n",
    "                \"Democrat\": [\"Democrat\", \"dem\", \"libs\", \"liberal\", \"left wing\", \"dnc\"],\n",
    "                \"Maga\": [\"Maga\", \"make america great again\"],\n",
    "                \"Islam\": [\"Islam\", \"muslim\", \"iran\", \"iraq\", \"israel\", \"middle east\",\"isis\"],\n",
    "                \"Fakenews\": [\"Fake news\",\"fakenews\",\"fox\",\"cnn\",\"msnbc\",\"WaPo\",\"Washington Post\",\"NYT\",\"New York Times\",\"HuffPost\",\"Huffington\",\"Yahoo\"],\n",
    "                \"Russia\": [\"Russia\"]\n",
    "               }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Right_Frequency</th>\n",
       "      <th>Left_Frequency</th>\n",
       "      <th>Right_Sentiment</th>\n",
       "      <th>Left_Sentiment</th>\n",
       "      <th>Right_Sentiment_Std</th>\n",
       "      <th>Left_Sentiment_Std</th>\n",
       "      <th>Right_Updates</th>\n",
       "      <th>Left_Updates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Trump</td>\n",
       "      <td>139455</td>\n",
       "      <td>28178</td>\n",
       "      <td>-0.035907</td>\n",
       "      <td>-0.069399</td>\n",
       "      <td>0.456759</td>\n",
       "      <td>0.456759</td>\n",
       "      <td>10070.070740</td>\n",
       "      <td>3576.116509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BlackLivesMatter</td>\n",
       "      <td>14513</td>\n",
       "      <td>53130</td>\n",
       "      <td>-0.145995</td>\n",
       "      <td>-0.018735</td>\n",
       "      <td>0.454990</td>\n",
       "      <td>0.454990</td>\n",
       "      <td>8034.139392</td>\n",
       "      <td>3078.636345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hillary</td>\n",
       "      <td>52230</td>\n",
       "      <td>5311</td>\n",
       "      <td>-0.085268</td>\n",
       "      <td>-0.013561</td>\n",
       "      <td>0.422539</td>\n",
       "      <td>0.422539</td>\n",
       "      <td>9004.150029</td>\n",
       "      <td>2584.819808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wall</td>\n",
       "      <td>10403</td>\n",
       "      <td>3785</td>\n",
       "      <td>-0.049571</td>\n",
       "      <td>0.063941</td>\n",
       "      <td>0.430326</td>\n",
       "      <td>0.430326</td>\n",
       "      <td>12549.104681</td>\n",
       "      <td>3792.928666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Obama</td>\n",
       "      <td>45185</td>\n",
       "      <td>5938</td>\n",
       "      <td>-0.107213</td>\n",
       "      <td>-0.016021</td>\n",
       "      <td>0.434051</td>\n",
       "      <td>0.434051</td>\n",
       "      <td>7752.373819</td>\n",
       "      <td>3443.387504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>America</td>\n",
       "      <td>135688</td>\n",
       "      <td>56162</td>\n",
       "      <td>-0.041184</td>\n",
       "      <td>0.004665</td>\n",
       "      <td>0.461271</td>\n",
       "      <td>0.461271</td>\n",
       "      <td>10244.696281</td>\n",
       "      <td>3618.212368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Republican</td>\n",
       "      <td>28177</td>\n",
       "      <td>6593</td>\n",
       "      <td>-0.034941</td>\n",
       "      <td>-0.055502</td>\n",
       "      <td>0.433535</td>\n",
       "      <td>0.433535</td>\n",
       "      <td>8166.365546</td>\n",
       "      <td>3034.659487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Democrat</td>\n",
       "      <td>59551</td>\n",
       "      <td>8762</td>\n",
       "      <td>-0.159778</td>\n",
       "      <td>-0.040120</td>\n",
       "      <td>0.446818</td>\n",
       "      <td>0.446818</td>\n",
       "      <td>9717.473796</td>\n",
       "      <td>3416.699612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Maga</td>\n",
       "      <td>18707</td>\n",
       "      <td>2317</td>\n",
       "      <td>0.045751</td>\n",
       "      <td>0.126126</td>\n",
       "      <td>0.453496</td>\n",
       "      <td>0.453496</td>\n",
       "      <td>18903.959641</td>\n",
       "      <td>3899.510574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Islam</td>\n",
       "      <td>42693</td>\n",
       "      <td>6939</td>\n",
       "      <td>-0.186188</td>\n",
       "      <td>-0.184455</td>\n",
       "      <td>0.447204</td>\n",
       "      <td>0.447204</td>\n",
       "      <td>6979.531492</td>\n",
       "      <td>3090.720421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Fakenews</td>\n",
       "      <td>35193</td>\n",
       "      <td>7394</td>\n",
       "      <td>-0.123897</td>\n",
       "      <td>-0.031851</td>\n",
       "      <td>0.431529</td>\n",
       "      <td>0.431529</td>\n",
       "      <td>15550.683261</td>\n",
       "      <td>3521.203814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Russia</td>\n",
       "      <td>11948</td>\n",
       "      <td>3546</td>\n",
       "      <td>-0.163501</td>\n",
       "      <td>-0.071404</td>\n",
       "      <td>0.420719</td>\n",
       "      <td>0.420719</td>\n",
       "      <td>13048.254017</td>\n",
       "      <td>4725.677383</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Topic  Right_Frequency  Left_Frequency  Right_Sentiment  \\\n",
       "0              Trump           139455           28178        -0.035907   \n",
       "1   BlackLivesMatter            14513           53130        -0.145995   \n",
       "2            Hillary            52230            5311        -0.085268   \n",
       "3               Wall            10403            3785        -0.049571   \n",
       "4              Obama            45185            5938        -0.107213   \n",
       "5            America           135688           56162        -0.041184   \n",
       "6         Republican            28177            6593        -0.034941   \n",
       "7           Democrat            59551            8762        -0.159778   \n",
       "8               Maga            18707            2317         0.045751   \n",
       "9              Islam            42693            6939        -0.186188   \n",
       "10          Fakenews            35193            7394        -0.123897   \n",
       "11            Russia            11948            3546        -0.163501   \n",
       "\n",
       "    Left_Sentiment  Right_Sentiment_Std  Left_Sentiment_Std  Right_Updates  \\\n",
       "0        -0.069399             0.456759            0.456759   10070.070740   \n",
       "1        -0.018735             0.454990            0.454990    8034.139392   \n",
       "2        -0.013561             0.422539            0.422539    9004.150029   \n",
       "3         0.063941             0.430326            0.430326   12549.104681   \n",
       "4        -0.016021             0.434051            0.434051    7752.373819   \n",
       "5         0.004665             0.461271            0.461271   10244.696281   \n",
       "6        -0.055502             0.433535            0.433535    8166.365546   \n",
       "7        -0.040120             0.446818            0.446818    9717.473796   \n",
       "8         0.126126             0.453496            0.453496   18903.959641   \n",
       "9        -0.184455             0.447204            0.447204    6979.531492   \n",
       "10       -0.031851             0.431529            0.431529   15550.683261   \n",
       "11       -0.071404             0.420719            0.420719   13048.254017   \n",
       "\n",
       "    Left_Updates  \n",
       "0    3576.116509  \n",
       "1    3078.636345  \n",
       "2    2584.819808  \n",
       "3    3792.928666  \n",
       "4    3443.387504  \n",
       "5    3618.212368  \n",
       "6    3034.659487  \n",
       "7    3416.699612  \n",
       "8    3899.510574  \n",
       "9    3090.720421  \n",
       "10   3521.203814  \n",
       "11   4725.677383  "
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df = defaultdict(list)\n",
    "right_troll_df['content'] = right_troll_df['content'].str.lower()\n",
    "left_troll_df['content'] = left_troll_df['content'].str.lower()\n",
    "\n",
    "# functions to find the frequency of common words and their avg sentiment from left and right account\n",
    "\n",
    "def calculateRightFrequency(termsList):\n",
    "    related_rows = right_troll_df[right_troll_df['content'].str.contains(\"|\".join(termsList))]\n",
    "    return len(related_rows)\n",
    "\n",
    "def calculateLeftFrequency(termsList):\n",
    "    related_rows = left_troll_df[left_troll_df['content'].str.contains(\"|\".join(termsList))]\n",
    "    return len(related_rows)\n",
    "\n",
    "def calculateRightSentiment(termsList):\n",
    "    related_rows = right_troll_df[right_troll_df['content'].str.contains(\"|\".join(termsList))]\n",
    "    return pd.to_numeric(related_rows[\"Compound_Score\"]).mean()\n",
    "\n",
    "def calculateLeftSentiment(termsList):\n",
    "    related_rows = left_troll_df[left_troll_df['content'].str.contains(\"|\".join(termsList))]\n",
    "    return pd.to_numeric(related_rows[\"Compound_Score\"]).mean()\n",
    "\n",
    "def calculateRightStdDev(termsList):\n",
    "    related_rows = right_troll_df[right_troll_df['content'].str.contains(\"|\".join(termsList))]\n",
    "    return pd.to_numeric(related_rows[\"Compound_Score\"]).std()\n",
    "\n",
    "def calculateLeftStdDev(termsList):\n",
    "    related_rows = left_troll_df[left_troll_df['content'].str.contains(\"|\".join(termsList))]\n",
    "    return pd.to_numeric(related_rows[\"Compound_Score\"]).std()\n",
    "\n",
    "def calculateRightUpdates(termsList):\n",
    "    related_rows = right_troll_df[right_troll_df['content'].str.contains(\"|\".join(termsList))]\n",
    "    return pd.to_numeric(related_rows[\"updates\"]).mean()\n",
    "\n",
    "def calculateLeftUpdates(termsList):\n",
    "    related_rows = left_troll_df[left_troll_df['content'].str.contains(\"|\".join(termsList))]\n",
    "    return pd.to_numeric(related_rows[\"updates\"]).mean()\n",
    "\n",
    "for term in search_terms:\n",
    "    search_terms[term] = [ t.lower() for t in search_terms[term] ]\n",
    "    final_df['Topic'].append(term)\n",
    "    final_df[\"Right_Frequency\"].append(calculateRightFrequency(search_terms[term]))\n",
    "    final_df[\"Left_Frequency\"].append(calculateLeftFrequency(search_terms[term]))\n",
    "    final_df[\"Right_Sentiment\"].append(calculateRightSentiment(search_terms[term]))\n",
    "    final_df[\"Left_Sentiment\"].append(calculateLeftSentiment(search_terms[term]))\n",
    "    final_df[\"Right_Sentiment_Std\"].append(calculateRightStdDev(search_terms[term]))\n",
    "    final_df[\"Left_Sentiment_Std\"].append(calculateRightStdDev(search_terms[term]))\n",
    "    final_df[\"Right_Updates\"].append(calculateRightUpdates(search_terms[term]))\n",
    "    final_df[\"Left_Updates\"].append(calculateLeftUpdates(search_terms[term]))\n",
    "\n",
    "final_df = pd.DataFrame(final_df)\n",
    "final_df.head(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>Neutral_Score</th>\n",
       "      <th>Negative_Score</th>\n",
       "      <th>Positive_Score</th>\n",
       "      <th>Compound_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35975</th>\n",
       "      <td>rt richardstiller4: polnewsforever ten_gop tha...</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.307</td>\n",
       "      <td>0.203</td>\n",
       "      <td>-0.3595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43986</th>\n",
       "      <td>new post: thanks obama! illegal alien satantis...</td>\n",
       "      <td>0.519</td>\n",
       "      <td>0.34600000000000003</td>\n",
       "      <td>0.135</td>\n",
       "      <td>-0.7712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80656</th>\n",
       "      <td>it's cheap and easy to say, \"thanks obama!\" th...</td>\n",
       "      <td>0.757</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.243</td>\n",
       "      <td>0.7263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93460</th>\n",
       "      <td>does it seem like everyone in the world wants ...</td>\n",
       "      <td>0.693</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.17800000000000002</td>\n",
       "      <td>0.128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165041</th>\n",
       "      <td>isis celebrates victory in ramadi ➠ thanks oba...</td>\n",
       "      <td>0.488</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.322</td>\n",
       "      <td>0.4019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  content Neutral_Score  \\\n",
       "35975   rt richardstiller4: polnewsforever ten_gop tha...          0.49   \n",
       "43986   new post: thanks obama! illegal alien satantis...         0.519   \n",
       "80656   it's cheap and easy to say, \"thanks obama!\" th...         0.757   \n",
       "93460   does it seem like everyone in the world wants ...         0.693   \n",
       "165041  isis celebrates victory in ramadi ➠ thanks oba...         0.488   \n",
       "\n",
       "             Negative_Score       Positive_Score Compound_Score  \n",
       "35975                 0.307                0.203        -0.3595  \n",
       "43986   0.34600000000000003                0.135        -0.7712  \n",
       "80656                   0.0                0.243         0.7263  \n",
       "93460                 0.129  0.17800000000000002          0.128  \n",
       "165041                 0.19                0.322         0.4019  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#look at tweets to see how the sentiment scores did on sarcasm\n",
    "(right_troll_df[right_troll_df[\"content\"].str.contains(\"thanks obama\")][[\"content\",\"Neutral_Score\",\"Negative_Score\",\"Positive_Score\",\"Compound_Score\"]]).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Left_Updates'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3062\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3063\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3064\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Left_Updates'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-121-300fb990631f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# y labels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0my_axis_right\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfinal_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Right_Updates\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0my_axis_left\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfinal_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Left_Updates\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m#circle labels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2683\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2684\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2685\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2686\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2687\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_getitem_column\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2690\u001b[0m         \u001b[1;31m# get column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2691\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2692\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2693\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2694\u001b[0m         \u001b[1;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_get_item_cache\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m   2484\u001b[0m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2485\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2486\u001b[1;33m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2487\u001b[0m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2488\u001b[0m             \u001b[0mcache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, item, fastpath)\u001b[0m\n\u001b[0;32m   4113\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4114\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4115\u001b[1;33m                 \u001b[0mloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4116\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4117\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0misna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3063\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3064\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3065\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3066\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3067\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Left_Updates'"
     ]
    }
   ],
   "source": [
    "# x labels\n",
    "right_sentiment = pd.DataFrame(final_df[\"Right_Sentiment\"])\n",
    "left_sentiment = pd.DataFrame(final_df[\"Left_Sentiment\"])\n",
    "x_axis = np.arange(-1, 1, .1)\n",
    "\n",
    "# y labels\n",
    "y_axis_right = pd.DataFrame(final_df[\"Right_Updates\"])\n",
    "y_axis_left = pd.DataFrame(final_df[\"Left_Updates\"])\n",
    "\n",
    "#circle labels\n",
    "labels = pd.DataFrame(final_df[\"Topic\"])\n",
    "\n",
    "# Build the scatter plots for each city type\n",
    "ax1 = topic.plot(kind='scatter',x=right_sentiment, y=\"1\",\n",
    "                       color=\"red\", s=final_df[\"Right_Sentiment\"], label = \"Right Sentiment\", \n",
    "                       alpha = 0.5, edgecolor = \"black\", linewidths = 1.5)    \n",
    "# ax2 = topic.plot(kind='scatter', x=x_axis, y=\"0\", \n",
    "#                           color=\"blue\",s=final_df[\"Left_Sentiment\"]*2, label = \"Left Sentiment\", \n",
    "#                           alpha = 0.5, edgecolor = \"black\", linewidths = 1.5, ax=ax1)    \n",
    "\n",
    "# plt.scatter(x_axis, final_df, marker=\"o\", facecolors=\"red\", edgecolors=\"black\",\n",
    "#             s=right_sentiment, alpha=0.75)\n",
    "\n",
    "\n",
    "# Incorporate the other graph properties\n",
    "plt.title(\"Sentiment of Most Used Words\")\n",
    "plt.xlabel(\"VADER Score\")\n",
    "plt.ylabel(\"Updates/Reactions\")\n",
    "\n",
    "# Create a legend\n",
    "plt.legend(title = 'TBD')\n",
    "plt.grid(True)\n",
    "\n",
    "# text label about the circle size\n",
    "textstr = \"Note: \\n Note Here.\"\n",
    "plt.text(42,35,textstr, fontsize=11)\n",
    "\n",
    "plt.show()\n",
    "# plt.savefig(\"Images/sentiment_leftandright.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make bars to connect the dots"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
